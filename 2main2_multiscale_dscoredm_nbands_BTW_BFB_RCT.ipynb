{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3797c54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mode=\"BTW_BFB_RCT_FGDA\"\n",
    "# mode=\"BTW_BFB_FGDA\"\n",
    "# mode=\"All_TWFB_RCT_FGDA\"\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "# from mne.decoding import CSP\n",
    "from pyriemann.spatialfilters import CSP\n",
    "from pyriemann.tangentspace import TangentSpace,FGDA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.pipeline import make_pipeline,Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import SVC\n",
    "from pyriemann.classification import SVC as rSVM\n",
    "from pyriemann.classification import MDM,FgMDM\n",
    "import numpy as np\n",
    "import moabb,sys,os,pickle,itertools\n",
    "from moabb.datasets import BNCI2014001\n",
    "from moabb.evaluations import CrossSessionEvaluation,WithinSessionEvaluation\n",
    "from moabb.paradigms import FilterBankMotorImagery,FilterBankLeftRightImagery, LeftRightImagery,MotorImagery\n",
    "from moabb.pipelines.utils import FilterBank\n",
    "from pyriemann.estimation import Covariances\n",
    "import pyriemann\n",
    "from time import time\n",
    "from san_utils import * \n",
    "from san_utils_rpa import *\n",
    "moabb.set_log_level(\"info\")\n",
    "\n",
    "############### load .pkl file #############3\n",
    "def loadfilters(direc,subject,n_filters):\n",
    "    with open(direc+'/sub_filters.pkl', 'rb') as file:\n",
    "        sub_filters=pickle.load(file)\n",
    "    with open(direc+'/timewin.pkl', 'rb') as file:\n",
    "        timewin=pickle.load( file)\n",
    "    bestfilters=sub_filters[subject][n_filters]\n",
    "    bestTW=timewin[subject]\n",
    "   \n",
    "    return bestfilters,bestTW\n",
    "\n",
    "# saving the results\n",
    "def save_csvfile(results,sfile_name):\n",
    "    if(os.path.isfile('./'+sfile_name) ==True):\n",
    "        print(\"exists\")\n",
    "        results.to_csv(sfile_name, mode=\"a\", index=False, header=False)\n",
    "    else:\n",
    "        print(\"No.. so creating\")\n",
    "        results.to_csv(sfile_name,  index=False, header=True) \n",
    "    return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "265c049d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = {}\n",
    "fb1 = FilterBank(make_pipeline(CSP(nfilter=4)))\n",
    "fb0 = FilterBank(make_pipeline(FGDA(),CSP(nfilter=4)))\n",
    "fb2 = FilterBank(make_pipeline(TangentSpace()))\n",
    "fb3 = FilterBank(make_pipeline(FGDA(),TangentSpace()))\n",
    "\n",
    "pipelines[\"FB_CSP_LDA\"] = make_pipeline(fb1, LDA())\n",
    "pipelines[\"FB_FGDA_CSP_LDA\"] = make_pipeline(fb0, LDA())\n",
    "pipelines[\"FB_CSP_SVM\"] = make_pipeline(fb1, SVC(kernel=\"linear\"))\n",
    "pipelines[\"FB_FGDA_CSP_SVM\"] = make_pipeline(fb0, SVC(kernel=\"linear\"))\n",
    "\n",
    "pipelines[\"FB_TS_LDA\"] = make_pipeline(fb2, LDA())\n",
    "pipelines[\"FB_TS_SVM\"] = make_pipeline(fb2, SVC(kernel=\"linear\"))\n",
    "pipelines[\"FB_FGDA_TS_LDA\"] = make_pipeline(fb3, LDA())\n",
    "pipelines[\"FB_FGDA_TS_SVM\"] = make_pipeline(fb3, SVC(kernel=\"linear\"))\n",
    "\n",
    "# pipelines[\"MDM\"] = make_pipeline(Covariances(\"oas\"), MDM(metric=\"riemann\"))\n",
    "# pipelines[\"FgMDM\"] = make_pipeline(Covariances(\"oas\"), FgMDM(metric=\"riemann\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb031e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FB_to_cov_rSVM(X):\n",
    "    x_sum_dist=[]\n",
    "    for i in range(X.shape[1]):\n",
    "        cov=X[:,i,:]\n",
    "        cov_sum=np.sum(cov, axis = 0)\n",
    "#         print(\"covsum:\",cov_sum.shape)\n",
    "        x_sum_dist.append(cov_sum) \n",
    "    x_sum_dist=np.array(x_sum_dist)\n",
    "    return x_sum_dist\n",
    "\n",
    "def FB_rSVM(X_train,y_train,X_test,y_test):\n",
    "    clf=rSVM(probability=True)\n",
    "#     print(X_train.shape,y_train.shape,np.unique(y_train))\n",
    "    yps=[]\n",
    "    for i in range(X_train.shape[-1]):\n",
    "        xt=X_train[:,:,:,i];xe=X_test[:,:,:,i]\n",
    "        clf.fit(xt,y_train); yp=clf.predict_proba(xe)\n",
    "        yps.append(yp)\n",
    "    yps=np.array(yps)\n",
    "#     print(yps.shape)\n",
    "    yprob=FB_to_cov_rSVM(yps)\n",
    "    y_pred=np.argmax(yprob, axis=1)\n",
    "    acc=accuracy_score(y_test,y_pred)\n",
    "    return acc, y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f83c17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = BNCI2014001()\n",
    "dataset_name=\"BNCI2014001\"\n",
    "subjects=[1,2,3,4,5,6,7,8,9]\n",
    "fmin = 4;fmax = 40; sfreq=250; n_class=4\n",
    "nbands_Sel=[7]#np.arange(1,18)\n",
    "nbs=[\"2468\",\"4\",\"24\",\"246\"]\n",
    "nbs=[\"4\"]\n",
    "\n",
    "flg=0\n",
    "\n",
    "for nb in nbs:\n",
    "    xt={};yt={};xe={};ye={}\n",
    "    fpath=dataset_name+\"/tw_fb\"+nb\n",
    "    sfile_name = fpath+\"/Ablation_accResults_CrossSess_\"+mode+\"_dscoredm_bands\"+nb+\".csv\"\n",
    "    #filtername=fpath+\"/filters.pkl\"\n",
    "    df = pd.DataFrame(columns=['dataset','session','channels','subject','n_filters','pipeline','acc',\n",
    "    'recall','precision','f1','kappa','sensitivity','specificity'])\n",
    "    for sub in subjects:\n",
    "        for nband in nbands_Sel:\n",
    "            print(\"subject:\",sub,\" || nbands:\",nband)\n",
    "            start_time = time()\n",
    "            bestfilters,bestTW=loadfilters(direc=fpath,subject=sub,n_filters=nband) #from .pkl file\n",
    "            end_time = time()\n",
    "            fetch_time=end_time - start_time\n",
    "            paradigm = FilterBankMotorImagery(filters=bestfilters,n_classes=n_class)\n",
    "            X, y, meta = paradigm.get_data(dataset=dataset, subjects=[sub])\n",
    "            if nband==1:\n",
    "                X=np.resize(X,(X.shape[0],X.shape[1],X.shape[2],1))\n",
    "            nchan=X.shape[1]\n",
    "            X=X[:,:,int(sfreq*bestTW[0]):int(sfreq*bestTW[1])]\n",
    "            select_indices = list(np.where(meta[\"session\"] == \"session_T\")[0])\n",
    "            X0=X[select_indices,:];y0=y[select_indices]\n",
    "            select_indices = list(np.where(meta[\"session\"] == \"session_E\")[0])\n",
    "            X1=X[select_indices,:];y1=y[select_indices]\n",
    "\n",
    "            if flg==0:\n",
    "                le,le_label_map=label_map_fn(y0) \n",
    "                flg=1\n",
    "\n",
    "            y0 = le.transform(y0);y1 = le.transform(y1)\n",
    "            start_time = time()\n",
    "            X_train, X_test, y_train, y_test=RCT_transform_nosplit(X0, X1, y0, y1)\n",
    "            end_time = time()\n",
    "            transform_time=end_time - start_time\n",
    "            \n",
    "            # X_train, X_test, y_train, y_test=calib_transform(X_train1, X_test1, y_train1, y_test1,target_train_split=10)\n",
    "            #X_train, X_test, y_train, y_test=RPA_transform(X_train1, X_test1, y_train1, y_test1,target_train_split=10)\n",
    "            # X_train, X_test, y_train, y_test=RCT_transform(X_train1, X_test1, y_train1, y_test1,target_train_split=10)\n",
    "            start_time = time()\n",
    "            X_train, X_test, y_train, y_test=no_transform_baseline(X0, X1, y0, y1)\n",
    "            end_time = time()\n",
    "            notransform_time=end_time - start_time\n",
    "            sys.exit()\n",
    "            xt[(sub,nband)]=X_train;   yt[(sub,nband)]=y_train\n",
    "            xe[(sub,nband)]=X_test;    ye[(sub,nband)]=y_test\n",
    "            print(X_train.shape,np.unique(y_train))\n",
    "            for pipe in pipelines.keys():\n",
    "                #print(pipe)\n",
    "                pipelines[pipe].fit(X_train, y_train)\n",
    "                y_pred=pipelines[pipe].predict(X_test)\n",
    "                acc,recall,precision,f1,kappa,sens,spec=all_metrics(y_test,y_pred)\n",
    "                print(pipe,\":\",acc)\n",
    "                #append row to the dataframe\n",
    "                df.loc[len(df)] = [dataset_name, \"session_E\", nchan, sub, nband, pipe, acc,recall,precision,f1,kappa,sens,spec]\n",
    "            #### FB_MDM ###\n",
    "            pipe=\"FB_MDM\"\n",
    "            fb4 = FilterBank(make_pipeline(MDM()), flatten=False)\n",
    "            a,y_pred=FB_MDM(X_train,y_train,X_test,y_test,fb4)\n",
    "            acc,recall,precision,f1,kappa,sens,spec=all_metrics(y_test,y_pred)\n",
    "            print(pipe,\":\",acc)\n",
    "            df.loc[len(df)] = [dataset_name, \"session_E\", nchan, sub, nband, pipe, acc,recall,precision,f1,kappa,sens,spec]\n",
    "            #### FB_FgMDM ###\n",
    "            pipe=\"FB_FgMDM\"\n",
    "            fb5 = FilterBank(make_pipeline(FgMDM()), flatten=False)\n",
    "            a,y_pred=FB_FgMDM(X_train,y_train,X_test,y_test,fb5)\n",
    "            acc,recall,precision,f1,kappa,sens,spec=all_metrics(y_test,y_pred)\n",
    "            print(pipe,\":\",acc)\n",
    "            df.loc[len(df)] = [dataset_name, \"session_E\", nchan, sub, nband, pipe, acc,recall,precision,f1,kappa,sens,spec]\n",
    "            #### FGDA_rSVM #####\n",
    "            pipe=\"FGDA_rSVM\"\n",
    "            fb6 = FilterBank(make_pipeline(FGDA()),flatten=False)\n",
    "            X_train1=fb6.fit_transform(X_train,y_train);X_test1=fb6.transform(X_test)\n",
    "            a,y_pred=FB_rSVM(X_train1,y_train,X_test1,y_test)\n",
    "            acc,recall,precision,f1,kappa,sens,spec=all_metrics(y_test,y_pred)\n",
    "            print(pipe,\":\",acc)\n",
    "            df.loc[len(df)] = [dataset_name, \"session_E\", nchan, sub, nband, pipe, acc,recall,precision,f1,kappa,sens,spec]\n",
    "            #### rSVM #####\n",
    "            pipe=\"rSVM\"\n",
    "            a,y_pred=FB_rSVM(X_train,y_train,X_test,y_test)\n",
    "            acc,recall,precision,f1,kappa,sens,spec=all_metrics(y_test,y_pred)\n",
    "            print(pipe,\":\",acc)\n",
    "            df.loc[len(df)] = [dataset_name, \"session_E\", nchan, sub, nband, pipe, acc,recall,precision,f1,kappa,sens,spec]\n",
    "            \n",
    "\n",
    "            \n",
    "            \n",
    "save_csvfile(df,sfile_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93d58bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### save X_train, X_test, y_train, y_test in .pkl file for 3Dcnn\n",
    "def save_pkl(xt,xe,yt,ye,le_map,direc):\n",
    "    with open(direc+'/xt_cnn_all.pkl', 'wb') as file:\n",
    "        pickle.dump(xt, file)\n",
    "    with open(direc+'/xe_cnn_all.pkl', 'wb') as file:\n",
    "        pickle.dump(xe, file)\n",
    "    with open(direc+'/yt_cnn_all.pkl', 'wb') as file:\n",
    "        pickle.dump(yt, file)\n",
    "    with open(direc+'/ye_cnn_all.pkl', 'wb') as file:\n",
    "        pickle.dump(ye, file) \n",
    "    with open(direc+'/le_map_cnn_all.pkl', 'wb') as file:\n",
    "        pickle.dump(le_map, file) \n",
    "\n",
    "save_pkl(xt,xe,yt,ye,le_label_map,fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bd94c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sfile_name='BNCI2014001/tw_fb4/plot_allbands_1_17.csv'\n",
    "# save_csvfile(df,sfile_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9adc2bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No.. so creating\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da23683",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "2793c4ebbbb80d1fc165d4801e8a6c765a804c7e7ba1d5682a1ddb1afca6cdeb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
