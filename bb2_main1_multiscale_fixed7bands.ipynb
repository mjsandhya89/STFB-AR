{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3797c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "# from mne.decoding import CSP\n",
    "from pyriemann.spatialfilters import CSP\n",
    "from pyriemann.tangentspace import TangentSpace\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.pipeline import make_pipeline,Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import numpy as np\n",
    "import moabb,sys,os\n",
    "from moabb.datasets import Zhou2016\n",
    "from moabb.evaluations import CrossSessionEvaluation,WithinSessionEvaluation\n",
    "from moabb.paradigms import FilterBankMotorImagery,FilterBankLeftRightImagery, LeftRightImagery,MotorImagery\n",
    "from moabb.pipelines.utils import FilterBank\n",
    "from pyriemann.estimation import Covariances\n",
    "import pyriemann\n",
    "from san_utils import *\n",
    "from pyriemann.classification import MDM,FgMDM\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "### FB_MDM  ###\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c0ecd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Zhou2016()\n",
    "dataset_name=\"Zhou2016\"\n",
    "allfilters=[[8, 12], [12, 16], [16, 20], [20, 24], [24, 28], [28, 34],[34,38]]\n",
    "subjects = [1, 2, 3,4]; n_class=3\n",
    "\n",
    "paradigm = MotorImagery(n_classes=n_class,fmin=8, fmax=30)\n",
    "X, y, meta = paradigm.get_data(dataset=dataset, subjects=[1])\n",
    "le,le_label_map=label_map_fn(y)\n",
    "nchan=X.shape[1]\n",
    "nfilt=len(allfilters)\n",
    "\n",
    "pipelines = {}\n",
    "fb1 = FilterBank(make_pipeline(Covariances(estimator=\"oas\"), CSP(nfilter=4)))\n",
    "fb2 = FilterBank(make_pipeline(Covariances(estimator=\"oas\"), TangentSpace()))\n",
    "\n",
    "pipelines[\"FBCSP+LDA\"] = make_pipeline(fb1, LDA())\n",
    "pipelines[\"FBCSP+SVM\"] = make_pipeline(fb1, SVC(kernel=\"linear\"))\n",
    "pipelines[\"FBTS+LDA\"] = make_pipeline(fb2, LDA())\n",
    "pipelines[\"FBTS+SVM\"] = make_pipeline(fb2, SVC(kernel=\"linear\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108809f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "paradigm = FilterBankMotorImagery(filters=allfilters,n_classes=n_class)\n",
    "df = pd.DataFrame(columns=['dataset','session','channels','subject','n_filters','pipeline',\n",
    "                           'acc','recall','precision','f1','kappa', 'sensitivity', 'specificity'])\n",
    "\n",
    "for subject in subjects:\n",
    "    print(\"subject:\",subject)\n",
    "    X, y, meta = paradigm.get_data(dataset=dataset, subjects=[subject])\n",
    "    ylab = le.transform(y)\n",
    "    select_indices = list(np.where(meta[\"session\"] == \"session_0\")[0])\n",
    "    X0=X[select_indices,:];y0=ylab[select_indices]\n",
    "    select_indices = list(np.where(meta[\"session\"] == \"session_1\")[0])\n",
    "    X1=X[select_indices,:];y1=ylab[select_indices]\n",
    "    select_indices = list(np.where(meta[\"session\"] == \"session_2\")[0])\n",
    "    X2=X[select_indices,:];y2=ylab[select_indices]\n",
    "    \n",
    "    #### FB CSP,TS classifiers ###\n",
    "    for pipeline in pipelines:\n",
    "        pipe=pipelines[pipeline]\n",
    "        pipe.fit(X0, y0)\n",
    "        yp1=pipe.predict(X1); yp2=pipe.predict(X2); \n",
    "        acc1,recall1,precision1,f11,kappa1,sens1,spec1=all_metrics(y1,yp1)\n",
    "        acc2,recall2,precision2,f12,kappa2,sens2,spec2=all_metrics(y2,yp2)\n",
    "        acc=(acc1+acc2)/2;recall=(recall1+recall2)/2;precision=(precision1+precision2)/2;f1=(f11+f12)/2;\n",
    "        kappa=(kappa1+kappa2)/2;sens=(sens1+sens2)/2;spec=(spec1+spec2)/2;\n",
    "        df.loc[len(df)] = [dataset_name, \"session_E\", nchan, subject, nfilt, pipeline, acc,recall,precision,f1,kappa,sens,spec]\n",
    "    #### FB_MDM ###\n",
    "    fb1 = FilterBank(make_pipeline(Covariances(estimator=\"oas\"),MDM()), flatten=False)\n",
    "    a,yp1=FB_MDM(X0, y0,X1,y1,fb1);a,yp2=FB_MDM(X0, y0,X2,y2,fb1)\n",
    "    acc1,recall1,precision1,f11,kappa1,sens1,spec1=all_metrics(y1,yp1)\n",
    "    acc2,recall2,precision2,f12,kappa2,sens2,spec2=all_metrics(y2,yp2)\n",
    "    acc=(acc1+acc2)/2;recall=(recall1+recall2)/2;precision=(precision1+precision2)/2;f1=(f11+f12)/2;\n",
    "    kappa=(kappa1+kappa2)/2;sens=(sens1+sens2)/2;spec=(spec1+spec2)/2;\n",
    "    df.loc[len(df)] = [dataset_name, \"session_E\", nchan, subject, nfilt, \"FB_MDM\", acc,recall,precision,f1,kappa,sens,spec]\n",
    "    #### FB_FgMDM ###\n",
    "    fb2 = FilterBank(make_pipeline(Covariances(estimator=\"oas\"),FgMDM()), flatten=False)\n",
    "    a,yp1=FB_FgMDM(X0, y0,X1,y1,fb2);a,yp2=FB_FgMDM(X0, y0,X2,y2,fb2)\n",
    "    acc1,recall1,precision1,f11,kappa1,sens1,spec1=all_metrics(y1,yp1)\n",
    "    acc2,recall2,precision2,f12,kappa2,sens2,spec2=all_metrics(y2,yp2)\n",
    "    acc=(acc1+acc2)/2;recall=(recall1+recall2)/2;precision=(precision1+precision2)/2;f1=(f11+f12)/2;\n",
    "    kappa=(kappa1+kappa2)/2;sens=(sens1+sens2)/2;spec=(spec1+spec2)/2;\n",
    "    df.loc[len(df)] = [dataset_name, \"session_E\", nchan, subject, nfilt, \"FB_FgMDM\", acc,recall,precision,f1,kappa,sens,spec]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dc8f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the results\n",
    "sfile_name = 'Zhou2016/baseline_fb/Results_multiscale_fixed7bands2.csv'\n",
    "\n",
    "if(os.path.isfile('./'+sfile_name) ==True):\n",
    "    print(\"exists\")\n",
    "    df.to_csv(sfile_name, mode=\"a\", index=False, header=False)\n",
    "else:\n",
    "    print(\"No.. so creating\")\n",
    "    df.to_csv(sfile_name,  index=False, header=True)    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8fb75a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "24f87bb250ad9690bdcbe6310002ee499af4cb3a4a0b060cf86bfc13b4180325"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
